{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferring signaling networks from multiple interventions with CORNETO\n",
    "\n",
    "This notebook illustrates how CORNETO can be used to learn the intracellular signaling network of a cell from multiple drug perturbations using prior knowledge, for which drug targets and RNA-seq data per perturbation is available. For this, we use the data from the [PANACEA DREAM Challenge](https://doi.org/10.1016/j.xcrm.2021.100492), which contains the gene expression profiles of cancer cell-lines treated with 32 different kinase inhibitors with known targets. The pipeline starts from two data files:\n",
    "\n",
    "- The gene counts matrix for the DU145 cell line, which can be downloaded from [here](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE186341)\n",
    "- The drug-target information, which can be obtained from the supplementary materials of the paper [here](https://ars.els-cdn.com/content/image/1-s2.0-S2666379121003694-mmc3.xlsx).\n",
    "\n",
    "The method infers the intracellular signaling network that recapitulates the observed changes in TF activities for each drug, by finding the minimal sub-graph from a Prior Knowledge Network that captures the signaling changes from drug targets to TFs. Typically, in a single contrast setting, the objective is to minimize the error between the predicted and observed changes in TF activity, with a regularization term that controls the size of the solution. This is how [CARNIVAL method](https://www.nature.com/articles/s41540-019-0118-z) works. In contrast, in the multi-condition setting, we extend this principle by minimizing the error between the predicted and observed changes in node activity across multiple conditions, while still controlling the size of the final solution in a single optimization problem. This results in a network that identifies better the signaling cascades by exploiting multiple independent interventions at the same time, instead of doing it independently.\n",
    "\n",
    "\n",
    "## Data preprocessing\n",
    "\n",
    "To run the analysis, we need to prepare the following data:\n",
    "\n",
    "- A signaling prior knowledge network, in the form of an activity flow network, which we obtain from [OmniPath](https://omnipathdb.org/).\n",
    "- The perturbed nodes in the network, which we obtain from the drug-target information.\n",
    "- The TF activity changes, which we obtain from the differential gene expression profiles using [DoRoThea](https://saezlab.github.io/dorothea/) and DecoupleR (https://saezlab.github.io/decoupleR).\n",
    "\n",
    "Processing of PANACEA data is done with processing.R script.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries, read data and prepare reaction network\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import corneto as cnt\n",
    "from corneto import Graph, create_flow_graph, signflow\n",
    "import os\n",
    "import re\n",
    "\n",
    "print(cnt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the folders in the current directory that start with 'run_'\n",
    "folders = [f for f in os.listdir('output/') if f.startswith('run_')]\n",
    "# Extract the numbers from the folders\n",
    "numbers = [int(re.search(r'\\d+', f).group()) for f in folders]\n",
    "# If there are no folders that start with 'run_', start the numbering at 1\n",
    "if not numbers:\n",
    "    next_number = 1\n",
    "else:\n",
    "    # Otherwise, find the next number by adding 1 to the maximum number in the list\n",
    "    next_number = max(numbers) + 1\n",
    "# Create the new folder with the next number\n",
    "folder = f\"output/run_{next_number:04d}\"\n",
    "os.mkdir(folder)\n",
    "print(f\"Created folder {folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "panacea_df = pd.read_csv(\"data.tsv\", sep=\"\\t\")\n",
    "pkn_df = pd.read_csv(\"pkn.tsv\", sep=\"\\t\")\n",
    "\n",
    "# filter panacea df only to features taht are in the source or target column of the pkn\n",
    "panacea_df = panacea_df[panacea_df[\"feature\"].isin(pkn_df['source'].unique()) | panacea_df[\"feature\"].isin(pkn_df['target'].unique())]\n",
    "\n",
    "pkn = cnt.import_sif(\"pkn.tsv\", has_header=True)\n",
    "\n",
    "# get perturbation_list as the list of unique ids in the feature column of the panacea df where the type is \"perturbation\"\n",
    "perturbation_list = panacea_df[panacea_df[\"type\"] == \"perturbation\"][\"feature\"].unique().tolist()\n",
    "measurement_list = panacea_df[panacea_df[\"type\"] == \"measurement\"][\"feature\"].unique().tolist()\n",
    "\n",
    "# prune the reaction network and prepare it for downstream analysis\n",
    "pruned_pkn = pkn.prune(perturbation_list, measurement_list)\n",
    "network = Graph.import_network(pruned_pkn)\n",
    "print(len(pkn.species), len(pkn.reactions))\n",
    "print(len(pruned_pkn.species), len(pruned_pkn.reactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare corneto input\n",
    "input_data = {}\n",
    "\n",
    "# iterate over each compound\n",
    "compounds = panacea_df[\"compound\"].unique()\n",
    "\n",
    "#### REMOVE THIS TO EXTEND TO ALL THE PERTURBATIONS ####\n",
    "#compounds = compounds[1:3]\n",
    "########################################################\n",
    "\n",
    "# iterate over compounds\n",
    "for compound in compounds:\n",
    "    compound_df = panacea_df[panacea_df[\"compound\"] == compound]\n",
    "    pert_df = compound_df[compound_df[\"type\"] == \"perturbation\"]\n",
    "    meas_df = compound_df[compound_df[\"type\"] == \"measurement\"]\n",
    "    # create dictionaries\n",
    "    pert_dict = {}\n",
    "    meas_dict = {}\n",
    "    # iterate over pert_df rows\n",
    "    for index, row in pert_df.iterrows():\n",
    "        pert_dict[row[\"feature\"]] = (\"P\", row[\"score\"])\n",
    "    for index, row in meas_df.iterrows():\n",
    "        meas_dict[row[\"feature\"]] = (\"M\", row[\"score\"])\n",
    "    \n",
    "    # concatenate both dictionaries\n",
    "    input_data[compound] = {**pert_dict, **meas_dict}\n",
    "\n",
    "flow_graph = create_flow_graph(network, input_data)\n",
    "print(flow_graph.num_species, flow_graph.num_reactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print conditions\n",
    "input_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = signflow(\n",
    "    flow_graph, \n",
    "    input_data, \n",
    "    l0_penalty_reaction = 0.1, \n",
    "    l0_penalty_species = 0.1\n",
    ")\n",
    "\n",
    "P = cp.solve(\n",
    "    'GUROBI', \n",
    "    verbosity=1,\n",
    "    NoRelHeurTime=8000,\n",
    "    MIPGap=0.02,\n",
    "    Method=1,\n",
    "    TimeLimit=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in cp.objectives:\n",
    "    print(o.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined variables in the flow problem\n",
    "cp.symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sol(pb, net):\n",
    "    df_edges = pd.DataFrame(\n",
    "        {'edges': net.reactions, \n",
    "         'flow': pb.symbols['_flow_rxn'].value,\n",
    "         'flow_indicator': np.abs(pb.symbols['_flow_rxn_ipos'].value)\n",
    "        }).set_index('edges')\n",
    "    for c in compounds:\n",
    "        act = np.abs(pb.symbols[f'reaction_sends_activation_{c}'].value)\n",
    "        inh = np.abs(pb.symbols[f'reaction_sends_inhibition_{c}'].value)\n",
    "        val = act - inh\n",
    "        df_edges[f'edge_value_{c}'] = val\n",
    "    df_nodes = pd.DataFrame({'nodes': net.species}).set_index('nodes')\n",
    "    for c in compounds:\n",
    "        act = np.abs(pb.symbols[f'species_activated_{c}'].value)\n",
    "        inh = np.abs(pb.symbols[f'species_inhibited_{c}'].value)\n",
    "        val = act - inh\n",
    "        df_nodes[f'{c}'] = val\n",
    "    return df_nodes, df_edges\n",
    "\n",
    "df_nodes, df_edges = get_sol(cp, flow_graph)\n",
    "df_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "normalize = mcolors.TwoSlopeNorm(vcenter=0, vmin=-1, vmax=1)\n",
    "sns.clustermap(df_nodes.loc[df_nodes.abs().sum(axis=1) > 1,:], cmap=cm.RdBu_r, norm=normalize)\n",
    "plt.savefig(f'{folder}/heatmap_activity_nodes.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove dummy nodes, drug targets and TFs and compare only unoobserved nodes\n",
    "observed = set()\n",
    "for k, v in input_data.items():\n",
    "    observed |= set(v.keys())\n",
    "predicted_nodes = list(set(df_nodes.index[~df_nodes.index.str.startswith('_')].values.tolist()).difference(observed))\n",
    "\n",
    "df_nodes_pred = df_nodes.loc[predicted_nodes,:]\n",
    "sns.clustermap(df_nodes_pred.loc[df_nodes_pred.abs().sum(axis=1) > 1,:], cmap=cm.RdBu_r, norm=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df_nodes.loc[df_nodes.abs().sum(axis=1) > 1,:].corr(), cmap=cm.RdBu_r, norm=normalize)\n",
    "plt.savefig(f'{folder}/heatmap_activity_nodes_corr_drugs.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df_nodes_pred.loc[df_nodes_pred.abs().sum(axis=1) > 1,:].corr(), cmap=cm.RdBu_r, norm=normalize)\n",
    "plt.savefig(f'{folder}/heatmap_activity_nodes_corr_drugs_only_predicted.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges.to_csv(f'{folder}/sol_edges.csv')\n",
    "df_nodes.to_csv(f'{folder}/sol_nodes.csv')\n",
    "df_nodes.loc[df_nodes.abs().sum(axis=1) > 1,:].corr().to_csv(f'{folder}/node_values_corr.csv')\n",
    "df_nodes_pred.loc[df_nodes_pred.abs().sum(axis=1) > 1,:].corr().to_csv(f'{folder}/node_values_corr_only_predicted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes.std(axis=1).sort_values(ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_nodes.abs().sum(axis=1).sort_values(ascending=False)).to_csv(f'{folder}/node_counts_sol.csv')\n",
    "pd.DataFrame(df_nodes.std(axis=1).sort_values(ascending=False)).to_csv(f'{folder}/node_std_sol.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3e619f447bdf7de6f81c339042b644d9e8ff07f44a83e3a355ce948a4f2e9ce6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
